{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "adfdemostevedf"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/AzureSqlTable2')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_onprem_udemycourse_db",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "id",
						"type": "int",
						"precision": 10
					},
					{
						"name": "json_data",
						"type": "varchar"
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "JsonInput"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/AzureSqlTable3')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_onprem_udemycourse_db",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "id",
						"type": "int",
						"precision": 10
					},
					{
						"name": "emp_name",
						"type": "varchar"
					},
					{
						"name": "salary",
						"type": "decimal",
						"precision": 19,
						"scale": 4
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "employee2"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SqlServerTable1')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_stevea_sqlserver",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"SchemaName": {
						"type": "string",
						"defaultValue": "HumanResources"
					},
					"TableName": {
						"type": "string",
						"defaultValue": "Employee"
					}
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [
					{
						"name": "BusinessEntityID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "NationalIDNumber",
						"type": "nvarchar"
					},
					{
						"name": "LoginID",
						"type": "nvarchar"
					},
					{
						"name": "OrganizationNode",
						"type": "hierarchyid"
					},
					{
						"name": "OrganizationLevel",
						"type": "smallint",
						"precision": 5
					},
					{
						"name": "JobTitle",
						"type": "nvarchar"
					},
					{
						"name": "BirthDate",
						"type": "date"
					},
					{
						"name": "MaritalStatus",
						"type": "nchar"
					},
					{
						"name": "Gender",
						"type": "nchar"
					},
					{
						"name": "HireDate",
						"type": "date"
					},
					{
						"name": "SalariedFlag",
						"type": "bit"
					},
					{
						"name": "VacationHours",
						"type": "smallint",
						"precision": 5
					},
					{
						"name": "SickLeaveHours",
						"type": "smallint",
						"precision": 5
					},
					{
						"name": "CurrentFlag",
						"type": "bit"
					},
					{
						"name": "rowguid",
						"type": "uniqueidentifier"
					},
					{
						"name": "ModifiedDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					}
				],
				"typeProperties": {
					"schema": {
						"value": "@dataset().SchemaName",
						"type": "Expression"
					},
					"table": {
						"value": "@dataset().TableName",
						"type": "Expression"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/az_ir_output_variable_demo')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_onprem_udemycourse_db",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_azuresql_database_copy_tables_dyn')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "sja"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_azuresql_db_all_tables')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "id",
						"type": "int",
						"precision": 10
					},
					{
						"name": "emp_name",
						"type": "varchar"
					},
					{
						"name": "salary",
						"type": "decimal",
						"precision": 19,
						"scale": 4
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "employee"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/sd_az_ir_param_demo')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"table_name": {
						"type": "string",
						"defaultValue": "employee"
					},
					"schema_name": {
						"type": "string",
						"defaultValue": "dbo"
					}
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "id",
						"type": "int",
						"precision": 10
					},
					{
						"name": "emp_name",
						"type": "varchar"
					},
					{
						"name": "salary",
						"type": "decimal",
						"precision": 19,
						"scale": 4
					}
				],
				"typeProperties": {
					"schema": {
						"value": "@dataset().schema_name",
						"type": "Expression"
					},
					"table": "employee"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_alter_row_transformation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_employees_csv",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable5",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1a"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 alterRow(deleteIf(Dept_id==3),",
						"     upsertIf(1==1)) ~> alterRow1a",
						"alterRow1a sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_key as integer,",
						"          Emp_id as integer,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:true,",
						"     keys:['Emp_id'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"srcsource sink(allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     partitionFileNames:['out.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          Emp_id,",
						"          Name,",
						"          Gender,",
						"          Salary,",
						"          Dept_id",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo_aggregate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						},
						{
							"dataset": {
								"referenceName": "ds_azure_dept",
								"type": "DatasetReference"
							},
							"name": "srcdept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"source(output(",
						"          Dept_id as integer,",
						"          Dept_Name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> srcdept",
						"srcsource aggregate(groupBy(Dept_id),",
						"     Count_employees = count(Emp_id),",
						"          avg_salary = avg(Salary)) ~> aggregate1",
						"aggregate1, srcdept join(aggregate1@Dept_id == srcdept@Dept_id,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo_conditional split')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "split1"
						},
						{
							"name": "union1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"srcsource split(equals(Dept_id, 1),",
						"     equals(Dept_id, 2),",
						"     disjoint: false) ~> split1@(ITemployees, HRemployees, Otheremployees)",
						"split1@ITemployees, split1@HRemployees, split1@Otheremployees union(byName: true)~> union1",
						"union1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo_exists')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable4",
								"type": "DatasetReference"
							},
							"name": "DeptSource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"source(output(",
						"          Dept_id as integer,",
						"          Dept_Name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> DeptSource",
						"srcsource, DeptSource exists(srcsource@Dept_id == DeptSource@Dept_id,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo_filter')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"srcsource filter(equals(Dept_id, 1),",
						"     partitionBy('roundRobin', 2)) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo_lookup_derived_columns')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						},
						{
							"dataset": {
								"referenceName": "ds_azure_dept",
								"type": "DatasetReference"
							},
							"name": "srcDept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"source(output(",
						"          Dept_id as integer,",
						"          Dept_Name as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> srcDept",
						"srcsource, srcDept lookup(srcsource@Dept_id == srcDept@Dept_id,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 derive(Salary_USD = divide(Salary, 80),",
						"          Dept_Name_new = iif(isNull(Dept_Name), 'Missing', Dept_Name),",
						"          Name = concat(Gender, '_',Name)) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo_pivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"srcsource pivot(groupBy(Dept_id),",
						"     pivotBy(Gender),",
						"     {} = count(Emp_id),",
						"     columnNaming: 'Total$N$V',",
						"     lateral: true) ~> pivot1",
						"pivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo_select')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"srcsource select(mapColumn(",
						"          Emp_id,",
						"          Dept_id,",
						"          EmpName = Name,",
						"          Salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     partitionFileNames:['out2.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_demo_sort_rank')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "sort1"
						},
						{
							"name": "rank1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"srcsource sort(desc(Salary, true)) ~> sort1",
						"sort1 rank(desc(Salary, true),",
						"     output(rank as long),",
						"     dense: true) ~> rank1",
						"rank1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_flatten_demo')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_employee_skill_json",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          emp_id as string,",
						"          emp_name as (first_name as string, last_name as string),",
						"          skills as string[]",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'arrayOfDocuments',",
						"     singleQuoted: true,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 foldDown(unroll(skills),",
						"     mapColumn(",
						"          emp_id,",
						"          emp_fname = emp_name.first_name,",
						"          emp_sname = emp_name.last_name,",
						"          skills",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_new_branch')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "df_ds_employee_csv",
								"type": "DatasetReference"
							},
							"name": "srcsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_adl_out",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						},
						{
							"name": "select2"
						},
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> srcsource",
						"select1 keyGenerate(output(EmpId as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"srcsource select(mapColumn(",
						"          Name,",
						"          Gender,",
						"          Salary,",
						"          Dept_id",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"surrogateKey1 select(mapColumn(",
						"          EmpId,",
						"          Name,",
						"          Gender,",
						"          Salary,",
						"          Dept_id",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select2",
						"srcsource aggregate(groupBy(Dept_id),",
						"     count_emp = count(Emp_id)) ~> aggregate1",
						"select2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as string,",
						"          Dept_id as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/df_scd2_demo')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_sql_csd2_source",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "ds_scd2_input",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sql_csd2_source",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "alterRow1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_key as integer,",
						"          Emp_id as integer,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as integer,",
						"          Is_Active as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"source(output(",
						"          Emp_id as integer,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 exists(source1@Emp_id == source2@Emp_id,",
						"     negate:false,",
						"     broadcast: 'auto')~> exists1",
						"exists1 derive(Is_Active = 'N') ~> derivedColumn1",
						"derivedColumn1 alterRow(updateIf(1==1)) ~> alterRow1",
						"alterRow1 select(mapColumn(",
						"          Emp_id,",
						"          Name,",
						"          Gender,",
						"          Salary,",
						"          Dept_id,",
						"          Is_Active",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_key as integer,",
						"          Emp_id as integer,",
						"          Name as string,",
						"          Gender as string,",
						"          Salary as integer,",
						"          Dept_id as integer,",
						"          Is_Active as string",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['Emp_id'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          Emp_id,",
						"          Name,",
						"          Gender,",
						"          Salary,",
						"          Dept_id,",
						"          Is_Active",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		}
	]
}